{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0dec7538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: faker in c:\\users\\girija s.h\\appdata\\roaming\\python\\python311\\site-packages (37.8.0)\n",
      "Requirement already satisfied: tzdata in c:\\users\\girija s.h\\appdata\\roaming\\python\\python311\\site-packages (from faker) (2025.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install faker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c1c3a28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: xgboost in c:\\users\\girija s.h\\appdata\\roaming\\python\\python311\\site-packages (3.0.5)\n",
      "Requirement already satisfied: numpy in c:\\users\\girija s.h\\appdata\\roaming\\python\\python311\\site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\girija s.h\\appdata\\roaming\\python\\python311\\site-packages (from xgboost) (1.15.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c288af62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16065a59",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4c6425a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434c90f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63386eb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26f562d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f858f70d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Improved Dataset Created. Shape: (500, 12)\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# ðŸ“Œ Student Cognitive Skills Analysis (Improved Dataset + ML + Clustering)\n",
    "# ============================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from faker import Faker\n",
    "import random\n",
    "\n",
    "# ML libraries\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ---------------------------\n",
    "# 1. Generate Synthetic Dataset\n",
    "# ---------------------------\n",
    "fake = Faker()\n",
    "random.seed(42)\n",
    "\n",
    "n_students = 500\n",
    "\n",
    "data = {\n",
    "    \"student_id\": [i for i in range(1, n_students + 1)],\n",
    "    \"name\": [fake.name() for _ in range(n_students)],\n",
    "    \"class\": [random.choice([\"A\", \"B\", \"C\", \"D\"]) for _ in range(n_students)],\n",
    "    \"comprehension\": np.random.randint(50, 100, n_students),\n",
    "    \"attention\": np.random.randint(40, 100, n_students),\n",
    "    \"focus\": np.random.randint(30, 100, n_students),\n",
    "    \"retention\": np.random.randint(20, 100, n_students),\n",
    "    \"engagement_time\": np.random.randint(10, 60, n_students)\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# ---------------------------\n",
    "# 2. Add Richer Features\n",
    "# ---------------------------\n",
    "df[\"concentration_synergy\"] = df[\"focus\"] * df[\"attention\"]\n",
    "df[\"learning_efficiency\"] = df[\"retention\"] / (df[\"engagement_time\"] + 1)  # avoid /0\n",
    "df[\"understand_and_retain\"] = df[\"comprehension\"] * df[\"retention\"]\n",
    "\n",
    "# ---------------------------\n",
    "# 3. Define Assessment Score (Target)\n",
    "# ---------------------------\n",
    "df[\"assessment_score\"] = (\n",
    "    0.3 * df[\"comprehension\"] +\n",
    "    0.25 * df[\"retention\"] +\n",
    "    0.2 * df[\"attention\"] +\n",
    "    0.15 * df[\"focus\"] +\n",
    "    0.1 * df[\"engagement_time\"] +\n",
    "    0.05 * df[\"concentration_synergy\"] / 100 +   # scaled\n",
    "    0.05 * df[\"learning_efficiency\"] +\n",
    "    0.05 * df[\"understand_and_retain\"] / 100 +\n",
    "    np.random.normal(0, 2, n_students)  # less noise\n",
    ").round(2)\n",
    "\n",
    "print(\"âœ… Improved Dataset Created. Shape:\", df.shape)\n",
    "df.head()\n",
    "\n",
    "# ---------------------------\n",
    "# 4. Train-Test Split\n",
    "# ---------------------------\n",
    "features = [\"comprehension\", \"attention\", \"focus\", \"retention\", \"engagement_time\",\n",
    "            \"concentration_synergy\", \"learning_efficiency\", \"understand_and_retain\"]\n",
    "\n",
    "X = df[features]\n",
    "y = df[\"assessment_score\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# ---------------------------\n",
    "# 5. Random Forest (Hyperparameter Tuning)\n",
    "# ---------------------------\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    RandomForestRegressor(random_state=42),\n",
    "    param_grid,\n",
    "    cv=5,\n",
    "    scoring='r2',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_rf = grid_search.best_estimator_\n",
    "y_pred_rf_test = best_rf.predict(X_test)\n",
    "\n",
    "print(\"\\nðŸŒ² Random Forest Results (Test Set)\")\n",
    "print(\"Best Params:\", grid_search.best_params_)\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred_rf_test))\n",
    "print(\"R2 Score:\", r2_score(y_test, y_pred_rf_test))\n",
    "\n",
    "# ---------------------------\n",
    "# 6. XGBoost Model\n",
    "# ---------------------------\n",
    "xgb = XGBRegressor(\n",
    "    n_estimators=300,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=5,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "xgb.fit(X_train, y_train)\n",
    "y_pred_xgb_test = xgb.predict(X_test)\n",
    "\n",
    "print(\"\\nðŸš€ XGBoost Results (Test Set)\")\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred_xgb_test))\n",
    "print(\"R2 Score:\", r2_score(y_test, y_pred_xgb_test))\n",
    "\n",
    "# ---------------------------\n",
    "# 7. Predict for Entire Dataset\n",
    "# ---------------------------\n",
    "df[\"predicted_score\"] = xgb.predict(df[features])\n",
    "\n",
    "# ---------------------------\n",
    "# 8. Clustering Students into Learning Personas\n",
    "# ---------------------------\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(df[features])\n",
    "\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "df[\"learning_persona\"] = kmeans.fit_predict(X_scaled)\n",
    "\n",
    "# ---------------------------\n",
    "# 9. Export Enriched Dataset\n",
    "# ---------------------------\n",
    "df.to_csv(\"students_results.csv\", index=False)\n",
    "print(\"âœ… Enriched dataset exported as 'students_results.csv'\")\n",
    "\n",
    "# ---------------------------\n",
    "# 10. Feature Importance (XGBoost)\n",
    "# ---------------------------\n",
    "xgb_importances = xgb.feature_importances_\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.barplot(x=features, y=xgb_importances)\n",
    "plt.xticks(rotation=45)\n",
    "plt.title(\"Feature Importance (XGBoost)\")\n",
    "plt.show()\n",
    "\n",
    "# ---------------------------\n",
    "# 11. Predicted vs Actual Scatter\n",
    "# ---------------------------\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.scatterplot(x=df[\"assessment_score\"], y=df[\"predicted_score\"])\n",
    "plt.plot([df[\"assessment_score\"].min(), df[\"assessment_score\"].max()],\n",
    "         [df[\"assessment_score\"].min(), df[\"assessment_score\"].max()],\n",
    "         'r--', lw=2)  # reference line\n",
    "plt.xlabel(\"Actual Assessment Score\")\n",
    "plt.ylabel(\"Predicted Score\")\n",
    "plt.title(\"Predicted vs Actual Assessment Score\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a59646",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3f279c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(df[features + [\"assessment_score\"]].corr(), annot=True, cmap=\"coolwarm\")\n",
    "plt.title(\"Correlation Matrix: Skills vs Assessment Score\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f669e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df, vars=features + [\"assessment_score\"], kind='scatter', diag_kind='kde')\n",
    "plt.suptitle(\"Pairplot of Cognitive Skills vs Assessment Score\", y=1.02)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be49f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "sns.histplot(df[\"assessment_score\"], bins=20, kde=True, color='skyblue')\n",
    "plt.title(\"Distribution of Assessment Scores\")\n",
    "plt.xlabel(\"Assessment Score\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428fd5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "sns.boxplot(x=\"class\", y=\"assessment_score\", data=df, palette=\"Set2\")\n",
    "plt.title(\"Assessment Score Distribution by Class\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d080b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "sns.scatterplot(x=df[\"attention\"], y=df[\"assessment_score\"],\n",
    "                hue=df[\"learning_persona\"], palette=\"viridis\", s=100)\n",
    "plt.title(\"Learning Personas: Attention vs Assessment Score\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4466b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = pd.Series(xgb.feature_importances_, index=features).sort_values(ascending=False)\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.barplot(x=importances.index, y=importances.values, palette=\"magma\")\n",
    "plt.title(\"Feature Importance (XGBoost)\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af798e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
